#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æè½¬å‘æ£€æµ‹ç»“æœ
å¸®åŠ©è¯†åˆ«å“ªäº›æ¨æ–‡å¯èƒ½è¢«è¯¯åˆ¤
"""

import json
import re

def analyze_tweet_classification(json_file):
    """åˆ†ææ¨æ–‡åˆ†ç±»ç»“æœ"""
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print("ğŸ” è½¬å‘æ£€æµ‹ç»“æœåˆ†æ")
    print("=" * 60)
    
    for user_data in data:
        username = user_data['username']
        tweets = user_data['recent_tweets']
        
        print(f"\nğŸ‘¤ ç”¨æˆ·: @{username}")
        print(f"ğŸ“Š æ€»æ¨æ–‡: {len(tweets)}")
        
        original_count = 0
        retweet_count = 0
        potential_misclassified = []
        
        for tweet in tweets[:10]:  # åˆ†æå‰10æ¡æ¨æ–‡
            is_retweet = tweet.get('is_retweet', False)
            full_text = tweet.get('full_text', '')
            tweet_text = tweet.get('text', '')
            
            # ç®€å•çš„è¯¯åˆ¤æ£€æµ‹é€»è¾‘
            has_reposted = 'reposted' in full_text.lower()
            has_pinned = 'pinned' in full_text.lower()
            
            if is_retweet:
                retweet_count += 1
                # æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯è¯¯åˆ¤
                if has_pinned and not has_reposted:
                    potential_misclassified.append({
                        'index': tweet['index'],
                        'reason': 'å¯èƒ½æ˜¯ç½®é¡¶åŸåˆ›æ¨æ–‡è¢«è¯¯åˆ¤ä¸ºè½¬å‘',
                        'text': tweet_text[:100] + '...' if len(tweet_text) > 100 else tweet_text
                    })
                elif not has_reposted and not re.search(r'RT @\w+', tweet_text):
                    potential_misclassified.append({
                        'index': tweet['index'],
                        'reason': 'åŸåˆ›å†…å®¹è¢«è¯¯åˆ¤ä¸ºè½¬å‘',
                        'text': tweet_text[:100] + '...' if len(tweet_text) > 100 else tweet_text
                    })
            else:
                original_count += 1
        
        print(f"âœï¸ åŸåˆ›: {original_count}")
        print(f"ğŸ”„ è½¬å‘: {retweet_count}")
        
        if potential_misclassified:
            print(f"\nâš ï¸ å¯èƒ½çš„è¯¯åˆ¤ ({len(potential_misclassified)}æ¡):")
            for item in potential_misclassified:
                print(f"  æ¨æ–‡ {item['index']}: {item['reason']}")
                print(f"    å†…å®¹: {item['text']}")
        
        # åˆ†æä¸€äº›æ ·æœ¬æ¨æ–‡çš„ç»“æ„
        print(f"\nğŸ” æ¨æ–‡ç»“æ„åˆ†æ (å‰3æ¡):")
        for i, tweet in enumerate(tweets[:3], 1):
            full_text = tweet.get('full_text', '')
            lines = full_text.split('\n')
            classification = "ğŸ”„è½¬å‘" if tweet.get('is_retweet', False) else "âœï¸åŸåˆ›"
            
            print(f"\n  æ¨æ–‡ {i} [{classification}]:")
            print(f"    å†…å®¹: {tweet.get('text', '')[:80]}...")
            print(f"    ç»“æ„: {len(lines)}è¡Œ")
            if len(lines) >= 2:
                print(f"    ç¬¬1è¡Œ: {lines[0][:50]}...")
                print(f"    ç¬¬2è¡Œ: {lines[1][:50]}..." if len(lines) > 1 else "")
        
        print("-" * 60)

if __name__ == "__main__":
    try:
        analyze_tweet_classification('results/twitter_users_data.json')
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° results/twitter_users_data.json æ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œçˆ¬è™«ç¨‹åºç”Ÿæˆæ•°æ®")
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")



