# Twitteræ¨æ–‡çˆ¬å–å·¥å…·(ä¸éœ€API) / Twitter Scraper Tool (No API Required)

[ä¸­æ–‡](#ä¸­æ–‡ç‰ˆ) | [English](#english-version)

---

## ä¸­æ–‡ç‰ˆ

è¿™æ˜¯ä¸€ä¸ªåŸºäºSeleniumçš„Twitteræ¨æ–‡çˆ¬å–å·¥å…·ï¼Œé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„è®¾è®¡ï¼Œå¯ä»¥è‡ªåŠ¨æœç´¢ç”¨æˆ·å¹¶è·å–å…¶æœ€æ–°æ¨æ–‡ã€‚

## åŠŸèƒ½ç‰¹ç‚¹

- ğŸ” è‡ªåŠ¨æœç´¢Twitterç”¨æˆ·
- ğŸ“ è·å–ç”¨æˆ·æœ€æ–°æ¨æ–‡ï¼ˆç›®æ ‡50æ¡ï¼‰
- ğŸ“Š æå–æ¨æ–‡å†…å®¹ã€æ—¥æœŸã€äº’åŠ¨æ•°æ®
- ğŸ‘¤ è·å–ç”¨æˆ·è¯¦ç»†ä¿¡æ¯ï¼ˆç²‰ä¸æ•°ã€ç®€ä»‹ã€è®¤è¯çŠ¶æ€ç­‰ï¼‰
- ğŸ—‚ï¸ æ”¯æŒJSONå’ŒTXTæ ¼å¼è¾“å‡º
- âš¡ ä½¿ç”¨ç°æœ‰æµè§ˆå™¨ä¼šè¯ï¼Œé¿å…é‡å¤ç™»å½•
- ğŸ“… æ™ºèƒ½æ’åºï¼šå·²çŸ¥æ—¥æœŸæ¨æ–‡æŒ‰æ—¶é—´æ’åºï¼ŒæœªçŸ¥æ—¥æœŸæ”¾åœ¨æœ€å
- ğŸ—ï¸ æ¨¡å—åŒ–æ¶æ„ï¼šåŠŸèƒ½åˆ†ç¦»ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•

## ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Windows 10/11
- **Pythonç‰ˆæœ¬**: Python 3.7+
- **æµè§ˆå™¨**: Google Chromeæµè§ˆå™¨ï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰
- **ç½‘ç»œè¿æ¥**: ç¨³å®šçš„äº’è”ç½‘è¿æ¥
- **å†…å­˜**: å»ºè®®4GBä»¥ä¸Šï¼ˆç”¨äºæµè§ˆå™¨å’ŒPythonç¨‹åºï¼‰

## å®‰è£…ä¾èµ–

é¡¹ç›®ä¾èµ–åŒ…å·²ä¼˜åŒ–ï¼Œä»…åŒ…å«å¿…è¦ç»„ä»¶ï¼š

```bash
pip install -r requirements.txt
```

**ä¸»è¦ä¾èµ–åŒ…**ï¼š
- `selenium==4.15.2` - æµè§ˆå™¨è‡ªåŠ¨åŒ–æ¡†æ¶
- `pandas==2.0.3` - æ•°æ®å¤„ç†å’Œåˆ†æ

## ä½¿ç”¨æ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šå¯åŠ¨Chromeè°ƒè¯•æ¨¡å¼

**æ–¹æ³•1ï¼šä½¿ç”¨æ‰¹å¤„ç†æ–‡ä»¶ï¼ˆæ¨èï¼‰**
```bash
# åŒå‡»è¿è¡Œ
start_chrome_debug.bat
```

**æ–¹æ³•2ï¼šä½¿ç”¨Pythonè„šæœ¬**
```bash
python start_chrome.py
```

**æ–¹æ³•3ï¼šæ‰‹åŠ¨å‘½ä»¤è¡Œ**
```bash
"C:\Users\David Wu\AppData\Local\Google\Chrome\Application\chrome.exe" --remote-debugging-port=9222 --user-data-dir=chrome_debug_profile
```

### ç¬¬äºŒæ­¥ï¼šåœ¨Chromeä¸­ç™»å½•Twitter

1. åœ¨æ–°æ‰“å¼€çš„Chromeçª—å£ä¸­è®¿é—® https://x.com/home
2. ç™»å½•æ‚¨çš„Twitterè´¦æˆ·
3. ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½

### ç¬¬ä¸‰æ­¥ï¼šè¿è¡Œçˆ¬å–ç¨‹åº

```bash
python twitter_search_with_existing_browser.py
```

## é…ç½®è¯´æ˜

### ç›®æ ‡ç”¨æˆ·åˆ—è¡¨

åœ¨ `twitter_search_with_existing_browser.py` ä¸­ä¿®æ”¹ `target_usernames` åˆ—è¡¨ï¼š

```python
target_usernames = [
    "sunyuchentron",
    "Defiqueen01",
    "ApeCryptos",
    "cryptodragon001",
    "Grandellaa",
    "CryptoAvenuee",
    "CryptoAs_TW",
    "specialist_005",
    "9ali9__",
    "CoinLabVerse"
]
```

### æ¨æ–‡æ•°é‡è®¾ç½®

é»˜è®¤è·å–50æ¡æ¨æ–‡ï¼Œå¯åœ¨è°ƒç”¨æ—¶ä¿®æ”¹ï¼š

```python
result = search_service.search_user_and_get_tweets(username, max_tweets=50)
```

## è¾“å‡ºæ–‡ä»¶

ç¨‹åºè¿è¡Œå®Œæˆåï¼Œä¼šåœ¨ `results/` ç›®å½•ä¸‹ç”Ÿæˆï¼š

- `twitter_users_data.json` - JSONæ ¼å¼çš„å®Œæ•´æ•°æ®
- `twitter_users_data.txt` - å¯è¯»çš„æ–‡æœ¬æ ¼å¼

### æ•°æ®æ ¼å¼

```json
{
  "username": "ç”¨æˆ·å",
  "display_name": "æ˜¾ç¤ºåç§°",
  "followers":"ç²‰ä¸æ•°",
  "description": "ä¸ªäººç®€ä»‹",
  "location": "ä½ç½®",
  "verified": false,
  "scraped_at": "çˆ¬å–æ—¶é—´",
  "url": "ç”¨æˆ·é¡µé¢é“¾æ¥",
  "recent_tweets": [
    {
      "index": 1,
      "text": "æ¨æ–‡å†…å®¹",
      "date": "å‘å¸ƒæ—¥æœŸ",
      "interactions": {
        "likes": "ç‚¹èµæ•°",
        "retweets": "è½¬å‘æ•°",
        "replies": "å›å¤æ•°",
        "views": "æµè§ˆæ•°"
      },
      "length": "å­—ç¬¦æ•°"
    }
  ]
}
```

## æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šæ— æ³•è¿æ¥åˆ°Chrome

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç¡®ä¿Chromeä»¥è°ƒè¯•æ¨¡å¼å¯åŠ¨
2. æ£€æŸ¥ç«¯å£9222æ˜¯å¦è¢«å ç”¨
3. é‡å¯Chromeæµè§ˆå™¨

### é—®é¢˜2ï¼šæ‰¾ä¸åˆ°Chromeæµè§ˆå™¨

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç¡®ä¿Chromeå·²æ­£ç¡®å®‰è£…
2. æ£€æŸ¥Chromeè·¯å¾„æ˜¯å¦æ­£ç¡®
3. ä½¿ç”¨å®Œæ•´è·¯å¾„å¯åŠ¨

### é—®é¢˜3ï¼šæ¨æ–‡æ•°é‡ä¸è¶³50æ¡

**å¯èƒ½åŸå› ï¼š**
- ç”¨æˆ·å®é™…æ¨æ–‡æ•°é‡å°‘äº50æ¡
- ç½‘ç»œè¿æ¥é—®é¢˜
- Twitteré¡µé¢åŠ è½½ä¸å®Œæ•´

**è§£å†³æ–¹æ¡ˆï¼š**
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- å¢åŠ ç­‰å¾…æ—¶é—´
- é‡æ–°è¿è¡Œç¨‹åº

### é—®é¢˜4ï¼šæ’åºé—®é¢˜

**å·²ä¿®å¤ï¼š**
- å·²çŸ¥æ—¥æœŸçš„æ¨æ–‡æŒ‰æ—¶é—´é¡ºåºæ’åˆ—
- æœªçŸ¥æ—¥æœŸçš„æ¨æ–‡æ”¾åœ¨æœ€å
- æ”¯æŒå¤šç§æ—¥æœŸæ ¼å¼è¯†åˆ«

## é¡¹ç›®æ¶æ„

### æ¨¡å—åŒ–è®¾è®¡

é¡¹ç›®é‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œå°†åŠŸèƒ½åˆ†ç¦»åˆ°ä¸åŒçš„æœåŠ¡æ¨¡å—ä¸­ï¼š

- **BaseService**: åŸºç¡€æœåŠ¡ç±»ï¼Œæä¾›æµè§ˆå™¨è¿æ¥ç­‰é€šç”¨åŠŸèƒ½
- **NavigationService**: å¯¼èˆªæœåŠ¡ï¼Œè´Ÿè´£é¡µé¢è·³è½¬å’ŒéªŒè¯
- **UserInfoExtractor**: ç”¨æˆ·ä¿¡æ¯æå–å™¨ï¼Œè·å–ç”¨æˆ·è¯¦ç»†ä¿¡æ¯
- **TweetExtractor**: æ¨æ–‡æå–å™¨ï¼Œè·å–å’Œè§£ææ¨æ–‡å†…å®¹
- **DataProcessor**: æ•°æ®å¤„ç†å™¨ï¼Œå¤„ç†å’Œæ ¼å¼åŒ–æ•°æ®
- **TwitterSearchService**: ä¸»æœç´¢æœåŠ¡ï¼Œæ•´åˆæ‰€æœ‰åŠŸèƒ½æ¨¡å—

## æ–‡ä»¶ç»“æ„

```
twitter_selenium_crawl/
â”œâ”€â”€ README.md                           # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ requirements.txt                     # Pythonä¾èµ–åŒ…
â”œâ”€â”€ twitter_search_with_existing_browser.py  # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ start_chrome_debug.bat              # Chromeå¯åŠ¨è„šæœ¬ï¼ˆWindowsæ‰¹å¤„ç†ï¼‰
â”œâ”€â”€ start_chrome.py                     # Chromeå¯åŠ¨Pythonè„šæœ¬
â”œâ”€â”€ services/                           # æ ¸å¿ƒæœåŠ¡æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_service.py                 # åŸºç¡€æœåŠ¡ç±»
â”‚   â”œâ”€â”€ navigation_service.py           # å¯¼èˆªæœåŠ¡
â”‚   â”œâ”€â”€ user_info_extractor.py          # ç”¨æˆ·ä¿¡æ¯æå–å™¨
â”‚   â”œâ”€â”€ tweet_extractor.py              # æ¨æ–‡æå–å™¨
â”‚   â”œâ”€â”€ data_processor.py               # æ•°æ®å¤„ç†å™¨
â”‚   â””â”€â”€ twitter_search_service.py       # ä¸»æœç´¢æœåŠ¡
â”œâ”€â”€ utils/                              # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ browser_utils.py               # æµè§ˆå™¨è¿æ¥å·¥å…·
â””â”€â”€ results/                           # è¾“å‡ºç›®å½•
    â”œâ”€â”€ twitter_users_data.json        # JSONæ ¼å¼æ•°æ®
    â””â”€â”€ twitter_users_data.txt         # æ–‡æœ¬æ ¼å¼æ•°æ®
```

## æŠ€æœ¯ç‰¹è‰²

### æ¨¡å—åŒ–æ¶æ„ä¼˜åŠ¿
- **èŒè´£åˆ†ç¦»**: æ¯ä¸ªæ¨¡å—ä¸“æ³¨äºç‰¹å®šåŠŸèƒ½ï¼Œä¾¿äºç»´æŠ¤
- **å¯æ‰©å±•æ€§**: æ˜“äºæ·»åŠ æ–°åŠŸèƒ½æˆ–ä¿®æ”¹ç°æœ‰åŠŸèƒ½
- **ä»£ç å¤ç”¨**: åŸºç¡€æœåŠ¡ç±»æä¾›é€šç”¨åŠŸèƒ½
- **é”™è¯¯éš”ç¦»**: æ¨¡å—é—´ç›¸å¯¹ç‹¬ç«‹ï¼Œé—®é¢˜ä¸ä¼šä¼ æ’­

### æ¨æ–‡è·å–ä¼˜åŒ–
- å‡å°æ»‘åŠ¨å¹…åº¦ï¼šæ¯æ¬¡æ»šåŠ¨400åƒç´ ï¼Œç¡®ä¿ä¸é—æ¼æ¨æ–‡
- å¢åŠ æ»šåŠ¨æ¬¡æ•°ï¼šæœ€å¤§500æ¬¡æ»šåŠ¨
- ä¼˜åŒ–ç­‰å¾…æ—¶é—´ï¼šæ¯æ¬¡æ»šåŠ¨åç­‰å¾…2ç§’
- æ— æ–°æ¨æ–‡å®¹å¿åº¦ï¼šè¿ç»­50æ¬¡æ— æ–°æ¨æ–‡æ‰åœæ­¢
- æ™ºèƒ½å»é‡ï¼šè‡ªåŠ¨è¯†åˆ«å’Œå»é™¤é‡å¤æ¨æ–‡

### ç”¨æˆ·ä¿¡æ¯æå–
- å®Œæ•´çš„ç”¨æˆ·èµ„æ–™ï¼šæ˜¾ç¤ºåç§°ã€ç”¨æˆ·åã€ç²‰ä¸æ•°ã€ç®€ä»‹ç­‰
- è®¤è¯çŠ¶æ€æ£€æµ‹ï¼šè‡ªåŠ¨è¯†åˆ«è®¤è¯ç”¨æˆ·
- å¤šé‡é€‰æ‹©å™¨ï¼šä½¿ç”¨å¤šç§CSSé€‰æ‹©å™¨ç¡®ä¿æ•°æ®è·å–æˆåŠŸ
- é”™è¯¯å¤„ç†ï¼šä¼˜é›…å¤„ç†ç¼ºå¤±æˆ–å¼‚å¸¸æ•°æ®

### æ—¥æœŸè¯†åˆ«ä¼˜åŒ–
- æ”¯æŒå¤šç§æ—¥æœŸæ ¼å¼ï¼šä¸­æ–‡æ—¥æœŸã€è‹±æ–‡ç¼©å†™ã€ç›¸å¯¹æ—¶é—´ç­‰
- æ”¹è¿›æ’åºé€»è¾‘ï¼šæ™ºèƒ½æ’åºç¡®ä¿æ—¶é—´é¡ºåºæ­£ç¡®
- æœªçŸ¥æ—¥æœŸå¤„ç†ï¼šç»Ÿä¸€æ”¾åœ¨æœ€åï¼Œé¿å…æ’åºæ··ä¹±

### æ•°æ®è¾“å‡ºä¼˜åŒ–
- åŒæ ¼å¼è¾“å‡ºï¼šJSONï¼ˆç»“æ„åŒ–ï¼‰å’ŒTXTï¼ˆå¯è¯»æ€§ï¼‰
- å­—ç¬¦ç»Ÿè®¡ï¼šæ¯æ¡æ¨æ–‡åŒ…å«å­—ç¬¦æ•°ç»Ÿè®¡
- ç´¢å¼•ç¼–å·ï¼šæ¨æ–‡æŒ‰é¡ºåºç¼–å·ï¼Œä¾¿äºå¼•ç”¨
- æ—¶é—´æˆ³è®°å½•ï¼šè®°å½•æ•°æ®çˆ¬å–æ—¶é—´

## æ³¨æ„äº‹é¡¹

1. **Chromeç‰ˆæœ¬**ï¼šå»ºè®®ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„Chromeæµè§ˆå™¨
2. **ç½‘ç»œè¿æ¥**ï¼šç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š
3. **Twitterç™»å½•**ï¼šç¡®ä¿åœ¨Chromeä¸­å·²ç™»å½•Twitterè´¦æˆ·
4. **ç”¨æˆ·æ•°æ®ç›®å½•**ï¼š`chrome_debug_profile` æ˜¯ç‹¬ç«‹çš„ç”¨æˆ·æ•°æ®ç›®å½•
5. **ç«¯å£å†²çª**ï¼šå¦‚æœ9222ç«¯å£è¢«å ç”¨ï¼Œå¯ä»¥ä¿®æ”¹ä¸ºå…¶ä»–ç«¯å£

## å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆéœ€è¦å¯åŠ¨Chromeè°ƒè¯•æ¨¡å¼ï¼Ÿ
A: è°ƒè¯•æ¨¡å¼å…è®¸Seleniumè¿æ¥åˆ°ç°æœ‰çš„Chromeä¼šè¯ï¼Œé¿å…é‡å¤ç™»å½•å’ŒéªŒè¯ç é—®é¢˜ã€‚

### Q: å¯ä»¥ä¿®æ”¹ç›®æ ‡ç”¨æˆ·åˆ—è¡¨å—ï¼Ÿ
A: å¯ä»¥ï¼Œåœ¨ `twitter_search_with_existing_browser.py` ä¸­ä¿®æ”¹ `target_usernames` åˆ—è¡¨ã€‚

### Q: æ¨æ–‡æ•°é‡æ€»æ˜¯50æ¡å—ï¼Ÿ
A: ä¸æ˜¯ï¼Œç¨‹åºä¼šå°è¯•è·å–50æ¡æ¨æ–‡ï¼Œä½†å®é™…æ•°é‡å–å†³äºç”¨æˆ·å‘å¸ƒçš„æ¨æ–‡æ•°é‡ã€‚

### Q: å¦‚ä½•å¤„ç†ç½‘ç»œé”™è¯¯ï¼Ÿ
A: ç¨‹åºä¼šè‡ªåŠ¨é‡è¯•ï¼Œå¦‚æœæŒç»­å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒTwitteré¡µé¢çŠ¶æ€ã€‚

## å¼€å‘æŒ‡å—

### æ·»åŠ æ–°åŠŸèƒ½æ¨¡å—

1. **åˆ›å»ºæ–°çš„æœåŠ¡ç±»**ï¼šç»§æ‰¿ `BaseService`
2. **å®ç°å¿…è¦æ–¹æ³•**ï¼šç¡®ä¿ä¸ç°æœ‰æ¨¡å—å…¼å®¹
3. **åœ¨ä¸»æœåŠ¡ä¸­é›†æˆ**ï¼šä¿®æ”¹ `TwitterSearchService`
4. **æ›´æ–°é…ç½®**ï¼šå¦‚éœ€è¦ï¼Œä¿®æ”¹ä¸»ç¨‹åºé…ç½®

### ä¿®æ”¹ç°æœ‰åŠŸèƒ½

1. **å®šä½ç›¸å…³æ¨¡å—**ï¼šæ ¹æ®åŠŸèƒ½ç±»å‹æ‰¾åˆ°å¯¹åº”çš„æœåŠ¡æ¨¡å—
2. **ä¿®æ”¹å…·ä½“å®ç°**ï¼šåœ¨ç›¸åº”çš„æå–å™¨æˆ–å¤„ç†å™¨ä¸­ä¿®æ”¹
3. **æµ‹è¯•éªŒè¯**ï¼šç¡®ä¿ä¿®æ”¹ä¸å½±å“å…¶ä»–åŠŸèƒ½

### æ‰©å±•æ•°æ®æ ¼å¼

1. **ä¿®æ”¹æå–å™¨**ï¼šåœ¨ç›¸åº”çš„æå–å™¨ä¸­æ·»åŠ æ–°å­—æ®µ
2. **æ›´æ–°æ•°æ®å¤„ç†**ï¼šåœ¨ `DataProcessor` ä¸­å¤„ç†æ–°æ•°æ®
3. **è°ƒæ•´è¾“å‡ºæ ¼å¼**ï¼šç¡®ä¿JSONå’ŒTXTè¾“å‡ºåŒ…å«æ–°å­—æ®µ

### ä»£ç è§„èŒƒ

- ä½¿ç”¨ä¸­æ–‡æ³¨é‡Šï¼Œä¾¿äºç†è§£
- éµå¾ªPython PEP 8è§„èŒƒ
- æ·»åŠ é€‚å½“çš„é”™è¯¯å¤„ç†
- åŒ…å«å¿…è¦çš„æ—¥å¿—è¾“å‡º

---

**æç¤º**ï¼šå¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·å…ˆæ£€æŸ¥Chromeæ˜¯å¦æ­£ç¡®å¯åŠ¨ï¼Œç„¶åç¡®ä¿åœ¨Chromeä¸­å·²ç™»å½•Twitterè´¦æˆ·ã€‚å¦‚éœ€å¼€å‘ç›¸å…³å¸®åŠ©ï¼Œè¯·å‚è€ƒå„æ¨¡å—çš„æ³¨é‡Šå’Œdocstringã€‚

---

## English Version

A Selenium-based Twitter scraping tool with modular architecture design that automatically searches for users and retrieves their latest tweets.

## Features

- ğŸ” Automatic Twitter user search
- ğŸ“ Retrieve user's latest tweets (target: 50 tweets)
- ğŸ“Š Extract tweet content, dates, and interaction data
- ğŸ‘¤ Get detailed user information (followers, bio, verification status, etc.)
- ğŸ—‚ï¸ Support for JSON and TXT format output
- âš¡ Use existing browser session to avoid repeated login
- ğŸ“… Smart sorting: known dates sorted by time, unknown dates placed last
- ğŸ—ï¸ Modular architecture: separated functionality for easy maintenance and extension

## System Requirements

- **Operating System**: Windows 10/11
- **Python Version**: Python 3.7+
- **Browser**: Google Chrome (latest version)
- **Network**: Stable internet connection
- **Memory**: 4GB+ recommended (for browser and Python program)

## Installation

Project dependencies are optimized with only essential components:

```bash
pip install -r requirements.txt
```

**Main Dependencies**:
- `selenium==4.15.2` - Browser automation framework
- `pandas==2.0.3` - Data processing and analysis

## Usage Steps

### Step 1: Start Chrome in Debug Mode

**Method 1: Using Batch File (Recommended)**
```bash
# Double-click to run
start_chrome_debug.bat
```

**Method 2: Using Python Script**
```bash
python start_chrome.py
```

**Method 3: Manual Command Line**
```bash
"C:\Users\David Wu\AppData\Local\Google\Chrome\Application\chrome.exe" --remote-debugging-port=9222 --user-data-dir=chrome_debug_profile
```

### Step 2: Login to Twitter in Chrome

1. Visit https://x.com/home in the newly opened Chrome window
2. Login to your Twitter account
3. Wait for the page to fully load

### Step 3: Run the Scraping Program

```bash
python twitter_search_with_existing_browser.py
```

## Configuration

### Target User List

Modify the `target_usernames` list in `twitter_search_with_existing_browser.py`:

```python
target_usernames = [
    "sunyuchentron",
    "Defiqueen01",
    "ApeCryptos",
    "cryptodragon001",
    "Grandellaa",
    "CryptoAvenuee",
    "CryptoAs_TW",
    "specialist_005",
    "9ali9__",
    "CoinLabVerse"
]
```

### Tweet Count Setting

Default retrieves 50 tweets, can be modified when calling:

```python
result = search_service.search_user_and_get_tweets(username, max_tweets=50)
```

## Output Files

After the program completes, files will be generated in the `results/` directory:

- `twitter_users_data.json` - Complete data in JSON format
- `twitter_users_data.txt` - Human-readable text format

### Data Format

```json
{
  "username": "username",
  "display_name": "display name",
  "followers": "follower count",
  "description": "bio",
  "location": "location",
  "verified": false,
  "scraped_at": "scraping time",
  "url": "user profile link",
  "recent_tweets": [
    {
      "index": 1,
      "text": "tweet content",
      "date": "publish date",
      "interactions": {
        "likes": "like count",
        "retweets": "retweet count",
        "replies": "reply count",
        "views": "view count"
      },
      "length": "character count"
    }
  ]
}
```

## Project Architecture

### Modular Design

The project uses modular architecture, separating functionality into different service modules:

- **BaseService**: Base service class providing common functionality like browser connection
- **NavigationService**: Navigation service for page jumping and verification
- **UserInfoExtractor**: User information extractor for detailed user info
- **TweetExtractor**: Tweet extractor for getting and parsing tweet content
- **DataProcessor**: Data processor for handling and formatting data
- **TwitterSearchService**: Main search service integrating all functional modules

## File Structure

```
twitter_selenium_crawl/
â”œâ”€â”€ README.md                           # Project documentation
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ twitter_search_with_existing_browser.py  # Main program entry
â”œâ”€â”€ start_chrome_debug.bat              # Chrome startup script (Windows batch)
â”œâ”€â”€ start_chrome.py                     # Chrome startup Python script
â”œâ”€â”€ services/                           # Core service modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_service.py                 # Base service class
â”‚   â”œâ”€â”€ navigation_service.py           # Navigation service
â”‚   â”œâ”€â”€ user_info_extractor.py          # User info extractor
â”‚   â”œâ”€â”€ tweet_extractor.py              # Tweet extractor
â”‚   â”œâ”€â”€ data_processor.py               # Data processor
â”‚   â””â”€â”€ twitter_search_service.py       # Main search service
â”œâ”€â”€ utils/                              # Utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ browser_utils.py               # Browser connection utilities
â””â”€â”€ results/                           # Output directory
    â”œâ”€â”€ twitter_users_data.json        # JSON format data
    â””â”€â”€ twitter_users_data.txt         # Text format data
```

## Technical Features

### Modular Architecture Advantages
- **Separation of Concerns**: Each module focuses on specific functionality for easy maintenance
- **Scalability**: Easy to add new features or modify existing ones
- **Code Reuse**: Base service class provides common functionality
- **Error Isolation**: Modules are relatively independent, preventing issue propagation

### Tweet Retrieval Optimization
- Reduced scroll amplitude: 400 pixels per scroll to ensure no tweets are missed
- Increased scroll count: maximum 500 scrolls
- Optimized wait time: 2 seconds after each scroll
- No new tweets tolerance: stops after 50 consecutive scrolls with no new tweets
- Smart deduplication: automatically identifies and removes duplicate tweets

### User Information Extraction
- Complete user profile: display name, username, follower count, bio, etc.
- Verification status detection: automatically identifies verified users
- Multiple selectors: uses various CSS selectors to ensure successful data retrieval
- Error handling: gracefully handles missing or abnormal data

### Date Recognition Optimization
- Support for multiple date formats: Chinese dates, English abbreviations, relative time, etc.
- Improved sorting logic: smart sorting ensures correct chronological order
- Unknown date handling: uniformly placed last to avoid sorting confusion

### Data Output Optimization
- Dual format output: JSON (structured) and TXT (readable)
- Character statistics: each tweet includes character count
- Index numbering: tweets numbered sequentially for easy reference
- Timestamp recording: records data scraping time

## Troubleshooting

### Issue 1: Cannot Connect to Chrome

**Solutions:**
1. Ensure Chrome is started in debug mode
2. Check if port 9222 is occupied
3. Restart Chrome browser

### Issue 2: Chrome Browser Not Found

**Solutions:**
1. Ensure Chrome is properly installed
2. Check if Chrome path is correct
3. Use full path to start

### Issue 3: Insufficient Tweet Count (Less than 50)

**Possible Causes:**
- User actually has fewer than 50 tweets
- Network connection issues
- Twitter page loading incomplete

**Solutions:**
- Check network connection
- Increase wait time
- Re-run the program

### Issue 4: Sorting Issues

**Fixed:**
- Known date tweets sorted chronologically
- Unknown date tweets placed last
- Support for multiple date format recognition

## Notes

1. **Chrome Version**: Recommend using the latest version of Chrome browser
2. **Network Connection**: Ensure stable network connection
3. **Twitter Login**: Ensure logged into Twitter account in Chrome
4. **User Data Directory**: `chrome_debug_profile` is an independent user data directory
5. **Port Conflicts**: If port 9222 is occupied, can modify to other ports

## FAQ

### Q: Why do I need to start Chrome in debug mode?
A: Debug mode allows Selenium to connect to existing Chrome sessions, avoiding repeated login and captcha issues.

### Q: Can I modify the target user list?
A: Yes, modify the `target_usernames` list in `twitter_search_with_existing_browser.py`.

### Q: Is the tweet count always 50?
A: No, the program tries to get 50 tweets, but actual count depends on the number of tweets the user has published.

### Q: How to handle network errors?
A: The program will automatically retry. If it continues to fail, check network connection and Twitter page status.

## Development Guide

### Adding New Feature Modules

1. **Create new service class**: Inherit from `BaseService`
2. **Implement necessary methods**: Ensure compatibility with existing modules
3. **Integrate in main service**: Modify `TwitterSearchService`
4. **Update configuration**: Modify main program configuration if needed

### Modifying Existing Features

1. **Locate relevant module**: Find corresponding service module based on feature type
2. **Modify specific implementation**: Make changes in appropriate extractor or processor
3. **Test and verify**: Ensure modifications don't affect other features

### Extending Data Formats

1. **Modify extractor**: Add new fields in corresponding extractor
2. **Update data processing**: Handle new data in `DataProcessor`
3. **Adjust output format**: Ensure JSON and TXT output include new fields

### Code Standards

- Use English comments for international collaboration
- Follow Python PEP 8 standards
- Add appropriate error handling
- Include necessary log output

---

**Tip**: If you encounter issues, first check if Chrome started correctly, then ensure you're logged into Twitter in Chrome. For development help, refer to comments and docstrings in each module. 
